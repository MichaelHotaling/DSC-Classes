{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Exercise: Building Your Text Classifiers <br> DSC550 <br> 2020-11-29 <br> Michael Hotaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **For this part, you will start by reading the controversial-comments.jsonl file into a DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Well it's great that he did something about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You are right Mr. President.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>You have given no input apart from saying I am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I am far from an expert on TPP and I would ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Thanks for playing. [I feel like her now](http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>i cant be racist, i have a black friend  \\n\\nl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Nope. You're right that they are both smoke an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>&amp;lt;That's exactly what it means. especially w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt\n",
       "0    0  Well it's great that he did something about th...\n",
       "1    0                       You are right Mr. President.\n",
       "2    0  You have given no input apart from saying I am...\n",
       "3    0  I get the frustration but the reason they want...\n",
       "4    0  I am far from an expert on TPP and I would ten...\n",
       "5    0  Thanks for playing. [I feel like her now](http...\n",
       "6    0                                          [deleted]\n",
       "7    0  i cant be racist, i have a black friend  \\n\\nl...\n",
       "8    0  Nope. You're right that they are both smoke an...\n",
       "9    0  &lt;That's exactly what it means. especially w..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataframe into Juypter\n",
    "# jsonl files require line = True to be interpreted correctly\n",
    "\n",
    "df = pd.read_json(\"controversial-comments.jsonl\",lines=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Convert all text to lowercase letters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each line needs to be coerced into a string and then we can pass the .lower() method to it\n",
    "# to change all characters to lower case\n",
    "\n",
    "df['txt'] = df['txt'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well it's great that he did something about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr. president.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks for playing. [i feel like her now](http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>i cant be racist, i have a black friend  \\n\\nl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>nope. you're right that they are both smoke an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>&amp;lt;that's exactly what it means. especially w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt\n",
       "0    0  well it's great that he did something about th...\n",
       "1    0                       you are right mr. president.\n",
       "2    0  you have given no input apart from saying i am...\n",
       "3    0  i get the frustration but the reason they want...\n",
       "4    0  i am far from an expert on tpp and i would ten...\n",
       "5    0  thanks for playing. [i feel like her now](http...\n",
       "6    0                                          [deleted]\n",
       "7    0  i cant be racist, i have a black friend  \\n\\nl...\n",
       "8    0  nope. you're right that they are both smoke an...\n",
       "9    0  &lt;that's exactly what it means. especially w..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Remove all punctuation from the text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Removing \\n (new lines)\n",
    "df[\"txt\"] = df['txt'].str.replace(\"\\n\", \" \")\n",
    "\n",
    "# Removing URLS\n",
    "df['txt'] = df['txt'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "df['txt'] = df['txt'].apply(lambda x: re.split('http:\\/\\/.*', str(x))[0])\n",
    "\n",
    "# Removing punctuation\n",
    "df[\"txt\"] = df['txt'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks for playing i feel like her now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>deleted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>i cant be racist i have a black friend    lolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>nope youre right that they are both smoke and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>ltthats exactly what it means especially when ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt\n",
       "0    0  well its great that he did something about tho...\n",
       "1    0                         you are right mr president\n",
       "2    0  you have given no input apart from saying i am...\n",
       "3    0  i get the frustration but the reason they want...\n",
       "4    0  i am far from an expert on tpp and i would ten...\n",
       "5    0             thanks for playing i feel like her now\n",
       "6    0                                            deleted\n",
       "7    0  i cant be racist i have a black friend    lolo...\n",
       "8    0  nope youre right that they are both smoke and ...\n",
       "9    0  ltthats exactly what it means especially when ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Remove stop words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the list of stop words\n",
    "\n",
    "stop = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new lines based on the old lines, while removing all words in the stop list\n",
    "# Each post must be transformed into a list of words split by spaces\n",
    "# Once that is done, we can apply our lambda function to recreate the list without stop words\n",
    "# This will return a list of words for each row\n",
    "\n",
    "df['txt'] = df['txt'].str.split().apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[well, great, something, beliefs, office, doub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[right, mr, president]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[given, input, apart, saying, wrong, argument,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[get, frustration, reason, want, way, foundati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[far, expert, tpp, would, tend, agree, lot, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>[thanks, playing, feel, like]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>[cant, racist, black, friend, lololol, vast, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>[nope, youre, right, smoke, smoke, bad, lungs,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>[ltthats, exactly, means, especially, power, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt\n",
       "0    0  [well, great, something, beliefs, office, doub...\n",
       "1    0                             [right, mr, president]\n",
       "2    0  [given, input, apart, saying, wrong, argument,...\n",
       "3    0  [get, frustration, reason, want, way, foundati...\n",
       "4    0  [far, expert, tpp, would, tend, agree, lot, pr...\n",
       "5    0                      [thanks, playing, feel, like]\n",
       "6    0                                          [deleted]\n",
       "7    0  [cant, racist, black, friend, lololol, vast, m...\n",
       "8    0  [nope, youre, right, smoke, smoke, bad, lungs,...\n",
       "9    0  [ltthats, exactly, means, especially, power, t..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Apply NLTK’s PorterStemmer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can define our stemming function here\n",
    "# First, we call the the PorterStemmer() class from nltk\n",
    "# I then created a temporary string to append all the stemmed words to.\n",
    "# We can the apply the Portstemmer to each word and add a space after each word to regenerate the sentence structure\n",
    "# We then return the entire string\n",
    "\n",
    "def stemmer(ser):\n",
    "    ps = PorterStemmer()\n",
    "    string = \"\"\n",
    "    for words in ser:\n",
    "        string += str(ps.stem(words)) + \" \"\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then apply the stemmer function to our series\n",
    "\n",
    "df['txt'] = df['txt'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well great someth belief offic doubt trump wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>right mr presid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>given input apart say wrong argument clearli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>get frustrat reason want way foundat complex p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>far expert tpp would tend agre lot problem und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>thank play feel like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>delet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>cant racist black friend lololol vast major mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>nope your right smoke smoke bad lung tobacco l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>ltthat exactli mean especi power take exist ri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt\n",
       "0    0  well great someth belief offic doubt trump wou...\n",
       "1    0                                   right mr presid \n",
       "2    0      given input apart say wrong argument clearli \n",
       "3    0  get frustrat reason want way foundat complex p...\n",
       "4    0  far expert tpp would tend agre lot problem und...\n",
       "5    0                              thank play feel like \n",
       "6    0                                             delet \n",
       "7    0  cant racist black friend lololol vast major mi...\n",
       "8    0  nope your right smoke smoke bad lung tobacco l...\n",
       "9    0  ltthat exactli mean especi power take exist ri..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving a backup of the cleaned data for the next exercises\n",
    "\n",
    "df.to_csv(\"cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You will apply three different techniques to get it into a usable form for model-building. Apply each of the following steps (individually) to the pre-processed data.**\n",
    "\n",
    "- **Convert each text entry into a word-count vector (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the size of the dataframe, we will need to take a sample to get our program to run\n",
    "\n",
    "dftest = df.sample(frac = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix \n",
    "\n",
    "# Calling the CountVectorizer method from sci-kit\n",
    "\n",
    "counter = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in the series into the CountVectorizer \n",
    "# Each line needs to be interpreted as Unicode in order for the program to work\n",
    "\n",
    "bag_of_words = counter.fit_transform(np.array(dftest['txt'].values.astype('U')))\n",
    "\n",
    "# Convert the bag_of_words to an array to generate the dataframe\n",
    "arr = bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000000000000</th>\n",
       "      <th>000000000000001</th>\n",
       "      <th>00000000000001</th>\n",
       "      <th>00000005</th>\n",
       "      <th>0000000566</th>\n",
       "      <th>000000143</th>\n",
       "      <th>000000554</th>\n",
       "      <th>000005</th>\n",
       "      <th>...</th>\n",
       "      <th>русский</th>\n",
       "      <th>сделали</th>\n",
       "      <th>спасибо</th>\n",
       "      <th>это</th>\n",
       "      <th>яepublican</th>\n",
       "      <th>яnew</th>\n",
       "      <th>яs</th>\n",
       "      <th>ترومپ</th>\n",
       "      <th>مرسی</th>\n",
       "      <th>ಠ_ಠ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47500 rows × 26938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  000000000000  000000000000001  00000000000001  00000005  \\\n",
       "0       0    0             0                0               0         0   \n",
       "1       0    0             0                0               0         0   \n",
       "2       0    0             0                0               0         0   \n",
       "3       0    0             0                0               0         0   \n",
       "4       0    0             0                0               0         0   \n",
       "...    ..  ...           ...              ...             ...       ...   \n",
       "47495   0    0             0                0               0         0   \n",
       "47496   0    0             0                0               0         0   \n",
       "47497   0    0             0                0               0         0   \n",
       "47498   0    0             0                0               0         0   \n",
       "47499   0    0             0                0               0         0   \n",
       "\n",
       "       0000000566  000000143  000000554  000005  ...  русский  сделали  \\\n",
       "0               0          0          0       0  ...        0        0   \n",
       "1               0          0          0       0  ...        0        0   \n",
       "2               0          0          0       0  ...        0        0   \n",
       "3               0          0          0       0  ...        0        0   \n",
       "4               0          0          0       0  ...        0        0   \n",
       "...           ...        ...        ...     ...  ...      ...      ...   \n",
       "47495           0          0          0       0  ...        0        0   \n",
       "47496           0          0          0       0  ...        0        0   \n",
       "47497           0          0          0       0  ...        0        0   \n",
       "47498           0          0          0       0  ...        0        0   \n",
       "47499           0          0          0       0  ...        0        0   \n",
       "\n",
       "       спасибо  это  яepublican  яnew  яs  ترومپ  مرسی  ಠ_ಠ  \n",
       "0            0    0           0     0   0      0     0    0  \n",
       "1            0    0           0     0   0      0     0    0  \n",
       "2            0    0           0     0   0      0     0    0  \n",
       "3            0    0           0     0   0      0     0    0  \n",
       "4            0    0           0     0   0      0     0    0  \n",
       "...        ...  ...         ...   ...  ..    ...   ...  ...  \n",
       "47495        0    0           0     0   0      0     0    0  \n",
       "47496        0    0           0     0   0      0     0    0  \n",
       "47497        0    0           0     0   0      0     0    0  \n",
       "47498        0    0           0     0   0      0     0    0  \n",
       "47499        0    0           0     0   0      0     0    0  \n",
       "\n",
       "[47500 rows x 26938 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe using the feature names as the column names.\n",
    "\n",
    "pd.DataFrame(arr, columns= counter.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1535)\t1\n",
      "  (0, 6411)\t1\n",
      "  (0, 7350)\t1\n",
      "  (0, 9564)\t1\n",
      "  (0, 14992)\t1\n",
      "  (0, 20266)\t1\n",
      "  (0, 23776)\t1\n",
      "  (0, 26811)\t1\n",
      "  (1, 3624)\t1\n",
      "  (1, 6151)\t1\n",
      "  (1, 7071)\t1\n",
      "  (1, 15292)\t1\n",
      "  (1, 19160)\t1\n",
      "  (1, 19177)\t1\n",
      "  (1, 20905)\t1\n",
      "  (1, 21155)\t1\n",
      "  (1, 21554)\t1\n",
      "  (1, 22939)\t1\n",
      "  (1, 24363)\t1\n",
      "  (1, 26337)\t1\n",
      "  (2, 3333)\t1\n",
      "  (2, 7422)\t1\n",
      "  (2, 12236)\t1\n",
      "  (2, 14139)\t1\n",
      "  (2, 14303)\t1\n",
      "  :\t:\n",
      "  (47497, 19570)\t1\n",
      "  (47497, 19594)\t1\n",
      "  (47497, 20989)\t1\n",
      "  (47497, 21165)\t1\n",
      "  (47497, 23533)\t1\n",
      "  (47497, 23639)\t1\n",
      "  (47498, 3154)\t1\n",
      "  (47498, 3399)\t1\n",
      "  (47498, 11647)\t1\n",
      "  (47498, 14264)\t1\n",
      "  (47499, 1795)\t1\n",
      "  (47499, 1994)\t1\n",
      "  (47499, 3300)\t1\n",
      "  (47499, 6233)\t1\n",
      "  (47499, 6291)\t2\n",
      "  (47499, 8278)\t1\n",
      "  (47499, 10377)\t1\n",
      "  (47499, 14053)\t1\n",
      "  (47499, 14303)\t1\n",
      "  (47499, 14323)\t2\n",
      "  (47499, 14992)\t1\n",
      "  (47499, 22622)\t1\n",
      "  (47499, 23462)\t1\n",
      "  (47499, 23934)\t2\n",
      "  (47499, 25853)\t2\n"
     ]
    }
   ],
   "source": [
    "# Reducing the sparse matrix down using csr_matrix from scipy\n",
    "\n",
    "print(csr_matrix(pd.DataFrame(arr, columns= counter.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Convert each text entry into a part-of-speech tag vector (see section 6.7 in the Machine Learning with Python Cookbook).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to generate part-of-speech tags for each line\n",
    "# The lines need to be split into a word list using split() or word_tokenize\n",
    "# Then we can pass the list of words into the part-of-speech function\n",
    "\n",
    "def part_of_speech_analyzer(arr):\n",
    "    tokens = []\n",
    "    for i in arr:\n",
    "        tokens.append(pos_tag(word_tokenize(str(i))))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>part-of-speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>797983</th>\n",
       "      <td>0</td>\n",
       "      <td>access doesnt mean damn thing your fuck right</td>\n",
       "      <td>[(access, NN), (doesnt, NN), (mean, VBP), (dam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868827</th>\n",
       "      <td>0</td>\n",
       "      <td>putin push blatantli say crimea direct militar...</td>\n",
       "      <td>[(putin, NN), (push, NN), (blatantli, NNS), (s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42551</th>\n",
       "      <td>0</td>\n",
       "      <td>lol suppos sure seem like dont believ illeg se...</td>\n",
       "      <td>[(lol, JJ), (suppos, JJ), (sure, JJ), (seem, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789237</th>\n",
       "      <td>0</td>\n",
       "      <td>protectionist polici domest industri plu immig...</td>\n",
       "      <td>[(protectionist, NN), (polici, NN), (domest, J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715901</th>\n",
       "      <td>0</td>\n",
       "      <td>hell liter content said said oh fox news never...</td>\n",
       "      <td>[(hell, NN), (liter, RBR), (content, NN), (sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468118</th>\n",
       "      <td>0</td>\n",
       "      <td>god miser veng petti peopl</td>\n",
       "      <td>[(god, NNS), (miser, RBR), (veng, RB), (petti,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566114</th>\n",
       "      <td>0</td>\n",
       "      <td>gtwe never ever ever get back togeth gtyou go ...</td>\n",
       "      <td>[(gtwe, NN), (never, RB), (ever, RB), (ever, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371861</th>\n",
       "      <td>0</td>\n",
       "      <td>realli dont care administr polit parti reason ...</td>\n",
       "      <td>[(realli, NN), (dont, NN), (care, NN), (admini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556686</th>\n",
       "      <td>0</td>\n",
       "      <td>hillari lobbi berni base</td>\n",
       "      <td>[(hillari, NN), (lobbi, NN), (berni, NN), (bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522234</th>\n",
       "      <td>0</td>\n",
       "      <td>gt cultur war alreadi begun escal lol mean tbh...</td>\n",
       "      <td>[(gt, JJ), (cultur, NN), (war, NN), (alreadi, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt  \\\n",
       "797983    0     access doesnt mean damn thing your fuck right    \n",
       "868827    0  putin push blatantli say crimea direct militar...   \n",
       "42551     0  lol suppos sure seem like dont believ illeg se...   \n",
       "789237    0  protectionist polici domest industri plu immig...   \n",
       "715901    0  hell liter content said said oh fox news never...   \n",
       "...     ...                                                ...   \n",
       "468118    0                        god miser veng petti peopl    \n",
       "566114    0  gtwe never ever ever get back togeth gtyou go ...   \n",
       "371861    0  realli dont care administr polit parti reason ...   \n",
       "556686    0                          hillari lobbi berni base    \n",
       "522234    0  gt cultur war alreadi begun escal lol mean tbh...   \n",
       "\n",
       "                                           part-of-speech  \n",
       "797983  [(access, NN), (doesnt, NN), (mean, VBP), (dam...  \n",
       "868827  [(putin, NN), (push, NN), (blatantli, NNS), (s...  \n",
       "42551   [(lol, JJ), (suppos, JJ), (sure, JJ), (seem, V...  \n",
       "789237  [(protectionist, NN), (polici, NN), (domest, J...  \n",
       "715901  [(hell, NN), (liter, RBR), (content, NN), (sai...  \n",
       "...                                                   ...  \n",
       "468118  [(god, NNS), (miser, RBR), (veng, RB), (petti,...  \n",
       "566114  [(gtwe, NN), (never, RB), (ever, RB), (ever, R...  \n",
       "371861  [(realli, NN), (dont, NN), (care, NN), (admini...  \n",
       "556686  [(hillari, NN), (lobbi, NN), (berni, NN), (bas...  \n",
       "522234  [(gt, JJ), (cultur, NN), (war, NN), (alreadi, ...  \n",
       "\n",
       "[47500 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the function to our series\n",
    "\n",
    "dftest['part-of-speech'] = part_of_speech_analyzer(dftest['txt'])\n",
    "dftest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Convert each entry into a term frequency-inverse document frequency (tfidf) vector (see section 6.9 in the Machine Learning with Python Cookbook).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889327</th>\n",
       "      <td>0</td>\n",
       "      <td>delet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145131</th>\n",
       "      <td>0</td>\n",
       "      <td>vast vast major far left peopl dont never use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9412</th>\n",
       "      <td>0</td>\n",
       "      <td>american vote trump im afraid proud read somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744165</th>\n",
       "      <td>0</td>\n",
       "      <td>3 day rule dont believ anyth news 3 day pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890017</th>\n",
       "      <td>0</td>\n",
       "      <td>poor guy want throw elect get sell book run te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476922</th>\n",
       "      <td>0</td>\n",
       "      <td>low ga price increas mpg standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420131</th>\n",
       "      <td>0</td>\n",
       "      <td>weak nottru answer usual refer lie excus lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560564</th>\n",
       "      <td>0</td>\n",
       "      <td>one say bad person judg order take care think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302528</th>\n",
       "      <td>0</td>\n",
       "      <td>well least someth good come trump presid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923003</th>\n",
       "      <td>0</td>\n",
       "      <td>nap centred around properti ancap thing much s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "889327    0                                             delet \n",
       "145131    0  vast vast major far left peopl dont never use ...\n",
       "9412      0  american vote trump im afraid proud read somet...\n",
       "744165    0      3 day rule dont believ anyth news 3 day pass \n",
       "890017    0  poor guy want throw elect get sell book run te...\n",
       "...     ...                                                ...\n",
       "476922    0                 low ga price increas mpg standard \n",
       "420131    0      weak nottru answer usual refer lie excus lie \n",
       "560564    0  one say bad person judg order take care think ...\n",
       "302528    0          well least someth good come trump presid \n",
       "923003    0  nap centred around properti ancap thing much s...\n",
       "\n",
       "[9500 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the library\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Taking a sample from the dataframe\n",
    "dftest = df.sample(frac = 0.01)\n",
    "\n",
    "# Checking the dataframe\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the TfidVectorizer() class from scikit\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Passing in the series into thr tfidf class as unicode\n",
    "feature_matrix = tfidf.fit_transform(dftest['txt'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00001</th>\n",
       "      <th>0005</th>\n",
       "      <th>001</th>\n",
       "      <th>007</th>\n",
       "      <th>00983</th>\n",
       "      <th>01</th>\n",
       "      <th>01508</th>\n",
       "      <th>016run</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zullo</th>\n",
       "      <th>zuriel45</th>\n",
       "      <th>ಠ_ಠ</th>\n",
       "      <th>눈_눈</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889327</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145131</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9412</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744165</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476922</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420131</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560564</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302528</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9500 rows × 12226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00  00001  0005  001  007  00983   01  01508  016run   02  ...  zip  \\\n",
       "889327  0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0     0.0  0.0  ...  0.0   \n",
       "145131  0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0     0.0  0.0  ...  0.0   \n",
       "9412    0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0     0.0  0.0  ...  0.0   \n",
       "744165  0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0     0.0  0.0  ...  0.0   \n",
       "890017  0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0     0.0  0.0  ...  0.0   \n",
       "...     ...    ...   ...  ...  ...    ...  ...    ...     ...  ...  ...  ...   \n",
       "476922  0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0     0.0  0.0  ...  0.0   \n",
       "420131  0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0     0.0  0.0  ...  0.0   \n",
       "560564  0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0     0.0  0.0  ...  0.0   \n",
       "302528  0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0     0.0  0.0  ...  0.0   \n",
       "923003  0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0     0.0  0.0  ...  0.0   \n",
       "\n",
       "        zodiac  zoloft  zombi  zone  zuckerberg  zullo  zuriel45  ಠ_ಠ  눈_눈  \n",
       "889327     0.0     0.0    0.0   0.0         0.0    0.0       0.0  0.0  0.0  \n",
       "145131     0.0     0.0    0.0   0.0         0.0    0.0       0.0  0.0  0.0  \n",
       "9412       0.0     0.0    0.0   0.0         0.0    0.0       0.0  0.0  0.0  \n",
       "744165     0.0     0.0    0.0   0.0         0.0    0.0       0.0  0.0  0.0  \n",
       "890017     0.0     0.0    0.0   0.0         0.0    0.0       0.0  0.0  0.0  \n",
       "...        ...     ...    ...   ...         ...    ...       ...  ...  ...  \n",
       "476922     0.0     0.0    0.0   0.0         0.0    0.0       0.0  0.0  0.0  \n",
       "420131     0.0     0.0    0.0   0.0         0.0    0.0       0.0  0.0  0.0  \n",
       "560564     0.0     0.0    0.0   0.0         0.0    0.0       0.0  0.0  0.0  \n",
       "302528     0.0     0.0    0.0   0.0         0.0    0.0       0.0  0.0  0.0  \n",
       "923003     0.0     0.0    0.0   0.0         0.0    0.0       0.0  0.0  0.0  \n",
       "\n",
       "[9500 rows x 12226 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the TFIDF data into a dataframe with the column names as feature names and \n",
    "# matching the index values to the associated entries\n",
    "\n",
    "pd.DataFrame(feature_matrix.toarray(), columns =tfidf.get_feature_names()).set_index(dftest.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2971)\t1.0\n",
      "  (1, 7410)\t0.3047124269826051\n",
      "  (1, 5195)\t0.1931497581513458\n",
      "  (1, 3137)\t0.13790987237666952\n",
      "  (1, 169)\t0.3047124269826051\n",
      "  (1, 1281)\t0.3047124269826051\n",
      "  (1, 6386)\t0.16266364761040605\n",
      "  (1, 2318)\t0.18363871141869217\n",
      "  (1, 11875)\t0.18253493990917322\n",
      "  (1, 10774)\t0.37695264571658954\n",
      "  (1, 11561)\t0.2843132879470299\n",
      "  (1, 7325)\t0.14507030633298978\n",
      "  (1, 3350)\t0.10885128462708425\n",
      "  (1, 8032)\t0.1018889866798203\n",
      "  (1, 6312)\t0.16772348012256974\n",
      "  (1, 4009)\t0.1624691444094898\n",
      "  (1, 6641)\t0.1686498802238612\n",
      "  (1, 11618)\t0.47164661617031794\n",
      "  (2, 8401)\t0.13343527703205804\n",
      "  (2, 11891)\t0.10848774532052306\n",
      "  (2, 8936)\t0.12888024698820438\n",
      "  (2, 2867)\t0.09464407411170876\n",
      "  (2, 8291)\t0.10577017980943523\n",
      "  (2, 8240)\t0.09170236898767316\n",
      "  (2, 4221)\t0.14314849623132325\n",
      "  :\t:\n",
      "  (9497, 4163)\t0.218376223733438\n",
      "  (9497, 7650)\t0.16379852656067267\n",
      "  (9497, 9395)\t0.19645459071433588\n",
      "  (9497, 1198)\t0.22724796029421382\n",
      "  (9497, 6644)\t0.17138924803910613\n",
      "  (9497, 10865)\t0.16209575041629062\n",
      "  (9497, 9468)\t0.16499078093518438\n",
      "  (9498, 6301)\t0.45716067668358945\n",
      "  (9498, 4662)\t0.3710190851055876\n",
      "  (9498, 8403)\t0.3659005834761926\n",
      "  (9498, 11862)\t0.37010730676595477\n",
      "  (9498, 2340)\t0.3933195048204363\n",
      "  (9498, 10108)\t0.40231921594698705\n",
      "  (9498, 11140)\t0.2567592535420238\n",
      "  (9499, 812)\t0.6539125033966229\n",
      "  (9499, 1992)\t0.32695625169831144\n",
      "  (9499, 7219)\t0.32695625169831144\n",
      "  (9499, 10511)\t0.31295146828908005\n",
      "  (9499, 808)\t0.30301491632729893\n",
      "  (9499, 8537)\t0.2411274621760425\n",
      "  (9499, 1000)\t0.18440484096649387\n",
      "  (9499, 7144)\t0.14836749763938112\n",
      "  (9499, 10863)\t0.133843305257063\n",
      "  (9499, 9395)\t0.1468321317237595\n",
      "  (9499, 9468)\t0.12331576468328925\n"
     ]
    }
   ],
   "source": [
    "# Reducing the sparse matrix down using csr_matrix from scipy\n",
    "\n",
    "print(csr_matrix(feature_matrix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
